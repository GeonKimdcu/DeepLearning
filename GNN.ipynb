{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5QfR7dW8vQKu2Nh/ZGMKR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeonKimdcu/DeepLearning-Textbook/blob/main/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN(Graph Neural Network)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Nq_--KYoGck7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 그래프"
      ],
      "metadata": {
        "id": "6hx8GB-QHjuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 그래프 정의 및 표현 방법"
      ],
      "metadata": {
        "id": "JjVUKXdrGcrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**그래프**는 <font color='#ff6f61'>점들과 그 점들을 잇는 선으로 이루어진 데이터 구조</font>이다. <br>\n",
        "주로 **관계**나 **상호작용**을 나타내는 데이터를 분석할 때 쓰인다. <br>\n",
        "대표적인 예로 페이스북 친구관계, 유튜브나 넷플릭스의 유저-영상 감상여부 등이 있다.\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149458150-76797a02-cf9b-4041-a24a-4749d0e68b67.png>\n",
        "\n",
        "Ref. Pixabay\n",
        "\n",
        "그 밖에 Graph data의 예는 아래와 같다.\n",
        "\n",
        "<img width=700 src=https://user-images.githubusercontent.com/48666867/149472857-0dbbdbbb-efcf-4cf1-a54f-86fd7d95a919.png>\n",
        "\n",
        "Ref. https://ganghee-lee.tistory.com/27"
      ],
      "metadata": {
        "id": "o-f3zkHnHfxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 그래프는 G=(V,E)로 정의하며 여기서 V는 점 집합(vertex or node)이고 E는 두 점을 잇는 선 집합(edge)이다. <br>\n",
        "\n",
        "<img width=150 src=https://user-images.githubusercontent.com/48666867/149458369-0574d775-e3e2-4b48-80e1-75d7a258beae.png>\n",
        "\n",
        "Ref. https://towardsdatascience.com\n",
        "\n",
        "예를 들어 위 그래프는 G=({1,2,3}, {{1,2}, {1,3}, {2,3}})으로 정의할 수 있다.\n",
        "\n",
        "data를 graph 형태로 나타내 보면, 하나의 node가 하나의 input data를 의미하고, edge는 두 data간의 relationship을 의미한다."
      ],
      "metadata": {
        "id": "v8EG0yMqIN_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프는 주로 **인접행렬**(adjacency matrix)로 표현된다. 점의 개수가 $n$개 일때 인접행렬의 크기는 $n \\times n$이다.<br>\n",
        "ML에서 그래프를 다룰 떈 점들의 특징을 묘사한 feature matrix로 표현하기도 하는데 feture의 개수가 $f$일 때 feature matrix의 차원은 $n \\times f$이다."
      ],
      "metadata": {
        "id": "V9nbrZNHI5L_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "graph data를 표현하기 위해선 모든 node 간의 relationship 정보를 담고있도록 data를 표현해야 한다. <br>\n",
        "따라서 이 정보들은 1) **Adjacency matrix**로 나타낼 수 있다. 또한 node 간의 relationship 정보 말고도 node(input data) 자체가 가지고 있는 feature 정보가 있으므로 이는 2) **Feature matrix**로 나타낸다. ($ex.$ Social Graph에서 한 명의 사람이 갖고 있는 정보 - 이름, 나이, 국가, 학력,...)\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149473963-e5580564-6d45-4b63-b69c-1f767a13eac2.png>\n",
        "\n",
        "1. **Network(Graph data)에서 Adjacency matrix를 만드는 방법**\n",
        "- 위 그림에서 가장 좌측에 있는 그림과 같은 Network가 존재할 때 $n$개의 node를 $n \\times n$ matrix로 표현해준다.\n",
        "- 이렇게 생성된 Adjacency matrix내의 value는 ($A_{ij} = i와\\;j의 \\;relationship\\;여부$)를 만족하는 value로 채워준다.\n",
        "\n",
        "2. **Feature matrix를 만드는 방법**\n",
        "- 각 input data에서 이용할 feature를 먼저 select한다.\n",
        "- Feature matrix에서 각 row는 선정한 feature에 대해 각 node가 갖는 값을 의미한다."
      ],
      "metadata": {
        "id": "5IrG98dfo-0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 그래프를 분석하기 어려운 이유"
      ],
      "metadata": {
        "id": "A7ZLrhTFJa09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. <font color='#ff6f61'>그래프는 **유클리드 공간**에 있지 않다.</font>\n",
        "- 이는 우리가 흔히 알고 있는 좌표계로 표현할 수 없다는 것을 의미한다. 시계열 데이터, 음성, 이미지 같은 데이터는 2차원, 3차원 유클리드 공간에 쉽게 매핑할 수 있지만 그래프 데이터의 해석은 비교적 어렵다\n",
        "2. <font color='#ff6f61'>그래프는 고정된 형태가 아니다.</font>\n",
        "- 아래 그림을 보면, 두 그래프는 다르게 생겼다. 하지만 두 그래프의 인접행렬은 같다. 이러한 경우, 두 그래프를 같게 봐야할까? 다르게 봐야할까?\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149458881-8fdf5bf7-b438-4957-b183-b78a0e512918.png>\n",
        "\n",
        "Ref. https://towardsdatascience.com\n",
        "\n",
        "- 이해가 쉽게 직접 인접행렬로 표현해보면 다음과 같다.\n",
        "- $\\begin{bmatrix}0&1&1&0&0\\\\1&0&1&0&0\\\\1&1&0&1&1\\\\0&0&1&0&1\\\\0&0&1&1&0 \\end{bmatrix}$\n",
        "\n",
        "3. <font color='#ff6f61'>그래프는 사람이 해석할 수 있도록 시각화 하는 것이 어렵다.</font>\n",
        "- 이 말은 위 예시에 있는 작은 그래프를 얘기하는 것이 아닌, 아래 그림에 있는 수천 개 이상인 그래프를 얘기하는 것이다. 점과 선들이 아주 밀접하게 붙어있어서 눈으로 보고 그래프를 이해하기 어렵다.\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149459679-87cfdea6-b8a3-4249-978a-0ed8ac9ba511.png>\n",
        "\n",
        "Ref. “Machine Learning and Structural Characteristics of Reverse Engineering”."
      ],
      "metadata": {
        "id": "H185Q485JdG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 그래프를 사용하는 이유"
      ],
      "metadata": {
        "id": "AaBN9C0pLSh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. <font color='#ff6f61'> 관계, 상호작용과 같은 추상적인 개념을 다루기에 적합하다.</font>\n",
        "- 그래프를 그려보면 이런 추상적인 개념을 시각화 할 때 도움이 된다. 사회적 관계를 분석할 때 기초가 되기도 한다.\n",
        "2. <font color='#ff6f61'>복잡한 문제를 더 간단한 표현으로 단순화하기도 하고 다른 관점으로 표현하여 해결할 수도 있다.</font>\n",
        "3. <font color='#ff6f61'>SNS, 미디어의 영향, 바이러스 확산 등을 연구하고 모델링할 때 사용할 수 있다.</font>\n",
        "- 소셜 네트워크의 분석은 데이터 과학에서 그래프 이론을 사용하는 가장 잘 알려진 분야일 것이다. 최근 뉴스에서 코로나 19 확산, 이동 경로를 나타내고 분석할 때도 자주 등장한다.\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149459951-ca55d7c5-277e-40bd-81d8-0371b7d264db.png>\n",
        "\n",
        "Ref. http://dj.kbs.co.kr/resources/2020-01-31/"
      ],
      "metadata": {
        "id": "mw8cMft8MKOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 기존 그래프 분석 방법"
      ],
      "metadata": {
        "id": "kgSWDo-fMzBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전통적인 방법은 주로 다음과 같은 알고리즘 기반 그래프 분석 방법이다.\n",
        "\n",
        "1. 검색 알고리즘(BFS, DFS 등)\n",
        "2. 최단 경로 알고리즘(Dijkstra 알고리즘, Floyd Warshall 등)\n",
        "3. 신장 트리 알고리즘(MST, Kruskal 알고리즘 등)\n",
        "4. 클러스터링 방법(연결 성분, 클러스터링 계수 등)\n",
        "\n",
        "이런 알고리즘의 한계는 알고리즘을 적용하기 전에 입력 그래프에 대한 사전 지식이 필요하다. <br>\n",
        "그렇기 때문에 그래프 자체를 연구하는 것이 불가능하고, 그래프 레벨에서의 예측이 불가능하다.\n",
        "\n",
        "---\n",
        "✨ '그래프 레벨'이란? 그래프에 속하는 점이나 선에 대한 정보를 다루는 것이 아닌, 그래프가 여러 개 있을 때 그래프의 정보를 다루는 것을 말한다."
      ],
      "metadata": {
        "id": "LD3mhtj7Nf2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Graph Neural Network"
      ],
      "metadata": {
        "id": "OmNJgJnfOWrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN은 이름에서도 알 수 있듯이 그래프에 직접 적용할 수 있는 신경망이다. 점 레벨에서, 선 레벨에서, 그래프 레벨에서의 예측 작업에 쓰인다.\n",
        "\n",
        "발표된 논문들을 보면 크게 세 가지로 나눌 수 있는데, \n",
        "1. Recurrent Graph Neural Network\n",
        "2. Spatial Convolutional Network\n",
        "3. Spectral Convolutional Network\n",
        "\n",
        "GNN의 핵심은 <font color='#ff6f61'> 점이 이웃과의 연결에 의해 정의</font>된다는 것이다. 만약 어떤 점의 이웃과 연결을 끊으면 그 점은 고립되고 아무 의미를 갖지 않게 된다.\n",
        "\n",
        "*이름을 불러주었을 때 꽃이 된다면, 연결될 때 점이 된다.* \n",
        "\n",
        "위 말을 상기한채로, 모든 점이 각각의 특징을 설명하는 어떤 상태로 표현되어 있다고 생각해보자. <br>\n",
        "예를 들어, 점이 영화고 이 영화는 로맨스, 범죄, 공포 중에 로맨스, 범죄에 해당한다면 (1,1,0)의 상태를 가지고 있다고 생각할 수 있다. <br>\n",
        "GNN은 주로 연결관계와 이웃들의 상태를 이용하여 각 점의 상태를 업데이트(학습)하고 마지막 상태를 통해 예측 업무를 수행한다. <br>\n",
        "일반적으로 마지막 상태를 <font color='#ff6f61'>'node embedding'</font>이라고 부른다."
      ],
      "metadata": {
        "id": "lITyzgTAOaJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 RecGNN(Recurrent Graph Neural Network)"
      ],
      "metadata": {
        "id": "9BkrkVdHPdvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RecGNN은 Banach Fixed-Point Theorem의 가정을 기반으로 한다. <br>\n",
        "Banach Fixed-Point Theorem은 다음과 같다.\n",
        "\n",
        "<img width=800 src=https://user-images.githubusercontent.com/48666867/149461429-9aae8a46-c87a-4a8a-9218-1a13969a3c2b.png>\n",
        "\n",
        "Ref. <a href=https://ieeexplore.ieee.org/document/4700287>Original GNN Paper</a>\n",
        "\n",
        "결국 간단히 얘기하자면, $k$가 크면, $x$에 매핑 $T$를 $k$번 적용한 값과 $k+1$번 적용한 값이 거의 같다는 의미로 이해하면 된다.\n",
        "\n",
        "$$x^k = T(x^{k-1}), k\\in (1,n)$$\n",
        "\n",
        "RecGNN에서 정의된 파라미터 함수를 살펴보면, \n",
        "\n",
        "$$x_n=f_w(l_n, l_{co[n]}, x_{ne[n]}, l_{ne[n]})$$\n",
        "\n",
        "- $l_{n}$는 점 $n$의 feature\n",
        "- $l_{co[n]}$은 점 $n$과 연결된 선들의 feature\n",
        "- $l_{ne[n]}$은 점 $n$과 연결된 점들의 feature이다.\n",
        "- $x_{ne[n]}$은 점 $n$과 연결된 점들의 상태를 의미한다.\n",
        "\n",
        "본 논문에서 쓰인 그림을 통해 이해해보자.\n",
        "\n",
        "<img width=500 src=https://user-images.githubusercontent.com/48666867/149462584-b10bda2a-b43f-4c98-a27d-7ef8a6c82766.png>\n",
        "\n",
        "$k$번 반복을 통한 업데이트 후 마지막 상태($x_n$)와 특징($l_n$)을 사용하여 결과 값($o_n$)을 출력한다. 즉, $o_n = g_w(x_n, l_n)$이 된다.\n",
        "\n",
        "---\n",
        "함수 $f_w, g_w$에 대한 자세한 내용은 본 논문에서 확인할 수 있다.\n",
        "\n"
      ],
      "metadata": {
        "id": "19w-OoADQOGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Spatial Convolutional Network"
      ],
      "metadata": {
        "id": "g8sYvoy3UjKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spatial Convolutional Network의 아이디어는 이미지 분류와 이미지 영역 구분에 많이 쓰이는 CNN의 아이디어와 비슷하다. <br>\n",
        "다시 말해서, 이미지에서 convolution의 아이디어는 학습 가능한 필터를 통해 중심 픽셀의 주변 픽셀을 합치는 것이다. Spatial Convolution Network의 핵심 아이디어는 이 아이디어에서 주변 픽셀 대신 연결된 점들의 특징을 적용한 것이다.\n",
        "\n",
        "<img width=700 src=https://user-images.githubusercontent.com/48666867/149463460-f963a4fc-bbb4-4891-8fe8-7bcbbcd6c16c.png>\n",
        "\n",
        "Ref. <a href=https://arxiv.org/abs/1901.00596>\"A Comprehensive Survey on Graph Neural Networks\"</a>\n",
        "\n",
        "<img width=700 src=https://user-images.githubusercontent.com/48666867/149463474-fbf08ac6-e92d-4d56-9bc7-198534c58ccc.png>\n",
        "\n",
        "Ref. http://dmqm.korea.ac.kr/activity/seminar/267"
      ],
      "metadata": {
        "id": "ii7wAGOkUrWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Spectral Convolutional Network\n",
        "\n",
        "Spectral Convolutional Network는 그래프 신호 처리 이론을 기반으로 고안됐으며 위에 설명한 것들보다 더 수학적 기반을 가지고 있다. \n",
        "\n",
        "<a href=https://arxiv.org/abs/1609.02907>해당 논문</a>에서 두 층으로 된 신경망을 제안하는데 아래 식으로 정리할 수 있다.\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149465785-4b36ae25-3663-4905-b420-d4303aa3528d.png>\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149465803-36ffa382-0f1d-4356-87bc-bf85922d1b6a.png>\n",
        "\n",
        "여기에서 $\\hat{A}$는 인접행렬 $A$를 약간 변형한 것이라고 생각하면 된다. fully-connected layer 두 개를 연결한 식에선 학습 가능한 행렬 $W$만 있는데 위 식엔 $\\hat{A}$이 붙어있다. (자세한 내용은 논문 참조)\n",
        "\n",
        "여기에선 인접행렬의 변형과 feature matrix를 곱하는 것이 어떤 의미인지만 살펴보도록 하자.\n",
        "\n",
        "<img width=350 src=https://user-images.githubusercontent.com/48666867/149467351-e50f9edb-8c01-4a10-bd00-5805f5bec5af.png>\n",
        "\n",
        "위와 같이 점이 4개인 그래프가 있을 떄, 위 그림처럼 연결되어 있고 점 옆에 있는 수들은 그래프의 feature를 나타낸다. 아래처럼 대각선을 1로 채운 인접행렬과 feature matrix를 쉽게 얻을 수 있다. <br>\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149467568-f985243b-363e-414a-967f-d99192283a17.png>\n",
        "\n",
        "이제 두 행렬을 곱해준다.\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149467609-458001dc-a7cb-45c4-8f20-7920afd56659.png>\n",
        "\n",
        "가장 오른쪽에 있는 행렬이 곱한 결과이다. <br>\n",
        "곱한 후 [점 1]의 feature를 보면, [점 1]자신과 이웃인 [점 2], [점 3]의 feature를 합한 값임을 알 수 있다. [점 4]는 [점 1]의 이웃이 아니므로 [점 4]의 feature는 더해지지 않았다. 인접행렬의 성질에 의해 곱한 결과가 자신과 이웃의 feature 합이 되었다.\n",
        "\n",
        "따라서 Spectral Convolutional Network와 Spatial Convolutional Network는 다른 내용을 기초로 하고 있지만 비슷한 연산 과정을 거친다. <br>\n",
        "현재 대두분의 Convolutional GNN이 이런 식이다."
      ],
      "metadata": {
        "id": "Rw19hnzMX-c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 GCN(Graph Convolution Network)"
      ],
      "metadata": {
        "id": "jf_jrwejHEt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GCN은 Graph network에 CNN에서의 Convolution 개념을 적용한 것이다.\n",
        "\n",
        "먼저 CNN의 특징을 살펴보자.\n",
        "\n",
        "1. Weight Sharing(가중치 공유)\n",
        "- CNN에서는 input data(ex. image)에 동일한 가중치를 갖는 동일한 filter를 이동하면서 연산을 진행한다. 이때 보통 스트라이드가 filter 크기보다 작게하여 이동시키므로 중복되어 연산되는 pixel이 다수 존재한다.\n",
        "- <img width=500 src=https://user-images.githubusercontent.com/48666867/149500282-d1bb5fb8-d98d-45a3-b305-3a0b4259fd91.png>\n",
        "\n",
        "2. Learn local features\n",
        "- 일반적인 MLP에서는 hidden node들이 모든 input node와 연결지어 있어서 global feature들에 의해 학습된다.\n",
        "- <img width=350 src=https://user-images.githubusercontent.com/48666867/149500587-b273e3e8-5dfd-4196-9b6d-e6842c7f9546.png>\n",
        "- 그러나 CNN에서는 filter가 이동하면서 local feature들이랑만 연산하고 activation map을 생성하므로 각 activation map의 pixe들은 global이 아닌 local feature들에 의해서만 학습된다고 볼 수 있다.\n",
        "- <img width=400 src=https://user-images.githubusercontent.com/48666867/149500899-ed7824fd-6219-4720-a2e0-de471809fb5d.png>\n",
        "\n",
        "따라서 CNN의 특징을 취합해보면 CNN에서는 동일한 가중치의 필터를 이동하면서 local feature들에 의해 node들을 학습시킨다. 이 과정에서 많은 중복 feature(=input pixel)들이 동일 가중치와 연산하기 때문에 output으로 나온 activation map의 pixel들은 근처 pixel끼리 상관 관계가 높아진다. <br>\n",
        "그렇기 때문에 Parallel Translation에 강해질 수 있다. ($e.g.$ Image를 1,2칸 shift해도 결과가 준수하게 나옴.)\n",
        "\n",
        "이러한 특성에 의해서 CNN은 근처 data끼리 상관 관계가 높은 input data에 대해 학습이 더 잘 이루어진다."
      ],
      "metadata": {
        "id": "upiThEfCHKTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그러면 이러한 특징들을 GCN에 어떻게 똑같이 적용시킬까? <br>\n",
        "Graph의 정보를 결정하는 것은 노드에 담긴 정보이다. 따라서 local 부분의 특성만 받아 동일 가중치로 연산하면서 노드 정보가 update되도록 해야한다.\n",
        "\n",
        "이 과정이 어떻게 이루어지는지 자세히 살펴보자.\n",
        "\n",
        "1) 먼저, Graph data를 표현하기 위해 위에서 언급한대로 Adjacency matrix, A와 Feature matrix, H를 만든다.(수식 notation을 위해 Feature matrix를 H라 칭한다.)\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149501945-fae47f4a-433f-4ca8-9190-0a1174442211.png>\n",
        "\n",
        "A행렬은 node 5개의 인접행렬이므로 $5 \\times 5$ shape을 갖는다. <br>\n",
        "H행렬은 $5\\times 10$ shape을 갖는데, row는 node 개수이고 column은 선택한 feature 개수를 임의로 10개로 정한 것이다.\n",
        "\n",
        "2) Hidden state는 $W$행렬과 $b$(bias)에 의해 update된다.($l$은 layer를 뜻함.)\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149502225-422b04c3-d281-421e-a4e7-73ab917f412c.png>\n",
        "\n",
        "- **Learn local feature**\n",
        "  - 만약 node 1이 2,3,4 node와 인접하고 있다고 가정하면, H1 state는 H1, H2, H3, H4에 의해서만 영향을 받아야한다.\n",
        "- **Weight sharing**\n",
        "  - 또한 동일 weight 행렬을 이용하여 H1, H2, H3, H4와 연산한다.\n",
        "- 즉, 각각의 H state는 자신과 연결된 state들과 W행렬을 곱한 후 모두 더한 값으로 update된다.\n",
        "\n",
        "이를 일반화시키면 다음과 같은 수식으로 표현할 수 있다. <br>\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149502766-54d83b09-efe8-460e-b028-18c973b970b9.png>\n",
        "\n",
        "이렇게 단순히 A행렬을 곱함으로써 일반화시킬 수 있다. <br>\n",
        "A 행렬을 HW에 곱하는 이유는 다음과 같다. <br>\n",
        "각각의 H state는 자신과 연결된 state에 의해서만 영향을 받는다. 이때 H와 W 행렬을 곱하여 나온 $H * W$ 행렬에서의 $(i,j)$ value는 $H_i * W_j$를 뜻한다.\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149503070-a5f483dc-f44a-48de-84fd-4bbb0c9d4e93.png>\n",
        "\n",
        "이때 $H*W$행렬에서 column N은 모든 H state들에 N번째 weight filter를 곱했을때 나온 값들이다.(weight sharing) <br>\n",
        "그러나 새롭게 update 되는 H state는 자신과 relationship이 있는 state와 동일 weight filter를 곱하여 나온 값들을 모두 더한 값이어야 한다. <br>\n",
        "즉, relationship에 대한 정보는 A행렬이 담고 있으므로 A행렬과 $H*W$행렬을 곱하게 되면 최종 output 행렬에서 $(i,j)$가 나타내는 value는 A 행렬에서 row i와 $H*W$행렬에서 column j를 곱한 값이다.\n",
        "\n",
        "A행렬에서 row i는 node i의 relationship 정보이고 $H*W$행렬에서 column j는 모든 H state에 j번째 weight filter를 곱한 값이다. 따라서 이 둘을 행렬 곱한것은 기존의 모든 H state에 j번째 weight filter를 곱하고 이 중에서 node i와 relationship이 있는 state만 더한 값으로 update를 한다는 뜻이다. (Learn local feature)\n",
        "\n",
        "<img width=700 src=https://user-images.githubusercontent.com/48666867/149507751-c75f0f0d-b812-403c-a5fe-9dd173e04a30.png>\n",
        "\n",
        "\n",
        "결과적으로 최종 output 행렬인 $H'$행렬에서 row i는 node i와 relationship이 있는 노드들을 각기 다른 weight filter와 연산해서 나온 value들이다.\n",
        "\n",
        "3) GCN을 거친 후 마지막에 Readout layer를 통해 최종적으로 classification 혹은 value regression 한다.\n",
        "- CNN에서 Conv-pool layer들을 거친 후 마지막에 모든 node들 정보를 취합하기 위해 FC-layer를 거친 후 softmax를 통해 classification 작업을 수행한다. <br>\n",
        "마찬가지로 Graph Neural Network에서도 graph convolution layer들을 거친 후 MLP로 모든 node 정보를 취합하고 최종적으로 regression 혹은 classification을 위해 어떤 값을 결정짓는 작업이 필요하다. 이를 GCN에서 readout-layer라고 한다.\n",
        "\n",
        "<img width=700 src=https://user-images.githubusercontent.com/48666867/149509746-16110a4d-117b-4ae9-a614-22c000608a56.png>\n",
        "\n",
        "- Readout layer가 필요한 이유 <br>\n",
        "같은 Network를 갖는 두 Graph가 인접행렬은 서로 다를 수 있다. 모든 노드 간의 edge 정보가 같아도 회전, 대칭에 의해 행렬 내 값의 순서가 다를 수 있기 때문이다. <br>\n",
        "따라서 이런 Permutation에 대해 invariance 하도록 하기 위해 MLP를 곱하는 readout-layer가 필요한 것이다.\n",
        "\n",
        "<img width=600 src=https://user-images.githubusercontent.com/48666867/149509916-8d861577-ef5e-423c-92be-ce0e4e400668.png>\n"
      ],
      "metadata": {
        "id": "yS01UvGxJK68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. GNN은 무엇을 할 수 있는가?"
      ],
      "metadata": {
        "id": "5i966A89fRyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN이 해결할 수 있는 문제는 크게 3가지로 나눌 수 있다."
      ],
      "metadata": {
        "id": "5k55EWysfR7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Node Classification"
      ],
      "metadata": {
        "id": "ZF2UqfDbfYxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Node embedding**을 통해 점들을 분류하는 문제다. <br>\n",
        "일반적으로 그래프이 일부만 레이블 된 상황에서 semi-supervised learning을 한다. <br>\n",
        "대표적인 응용 영역으로는 인용 네트워크, Reddit 게시물, Youtube 동영상이 있다.\n",
        "\n",
        "<img width=250 src=https://user-images.githubusercontent.com/48666867/149472492-44b916a9-bd1c-45fb-af55-b079f95c24bb.png>"
      ],
      "metadata": {
        "id": "C_bovzNGfg4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Link Prediction"
      ],
      "metadata": {
        "id": "8QsNMJ8FfhA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프의 점들 사이의 관계를 파악하고 두 점 사이에 얼마나 연관성이 있을지 예측하는 문제다. <br>\n",
        "대표적인 예로 페이스북 친구 추천, 유튜브 또는 넷플릭스 영상 추천 등이 있다. \n",
        "\n",
        "영화와 유저가 점이고 유저가 영화를 봤을 경우 선으로 연결을 해준 그래프를 생각할 수 있다. 선으로 연결되지 않은 영화, 유저 쌍 중에 연결될 가능성이 높은 쌍을 찾아서 유저가 영화를 감상할 가능성이 높다고 예측할 수 있다.\n",
        "\n",
        "<img width=400 src=https://user-images.githubusercontent.com/48666867/149472588-568a7837-870c-4a44-897c-cb7fe12cdf2c.png>"
      ],
      "metadata": {
        "id": "9IH0esmZf34J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Graph Classification\n",
        "\n",
        "그래프 전체를 여러가지 카테고리로 분류하는 문제다. <br>\n",
        "이미지 분류와 비슷하지만 대상이 그래프라고 이해하면 된다. 분자 구조가 그래프의 형태로 제공되어 그걸 분류하는 산업 문제에 광범위하게 적용할 수 있으며 따라서 화학, 생의학, 물리학 연구자들과 활발히 협업을 하고 있다.\n",
        "\n",
        "<img width=300 src=https://user-images.githubusercontent.com/48666867/149472691-efa95a26-4bd8-41fc-be11-2755945e2b07.png>"
      ],
      "metadata": {
        "id": "BMjiFTo2gNzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 실제 응용 사례"
      ],
      "metadata": {
        "id": "PW5t6ed9gbY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Scene graph generation by iterative message passing"
      ],
      "metadata": {
        "id": "LGzN6EsQgdtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN에 기반을 둔 많은 방법들이 이미지에서 물체를 탐지하는데 최첨단 성능을 달성했지만 그 물체들 사이의 관계까지는 알지 못한다. CNN으로 탐지된 물체들을 아래 그림의 방법을 통해 scene graph를 만들어서 관계를 파악할 수 있다.\n",
        "\n",
        "<img width=900 src=https://user-images.githubusercontent.com/48666867/149469041-9229ce3c-b0d2-404b-b0ec-306d4c2a7eb3.png>"
      ],
      "metadata": {
        "id": "NLchkB9egjaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Image generation from scene graphs"
      ],
      "metadata": {
        "id": "6gUuB5f9hD8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 언급한 작업의 반대되는 작업도 할 수 있다. 기존 이미지 생성 방법은 GAN이나 Autoencoder를 사용하였다. <br>\n",
        "아래 그림의 방법을 사용하면 scene graph로 부터 이미지를 생성할 수 있다.\n",
        "\n",
        "<img width=900 src=https://user-images.githubusercontent.com/48666867/149469252-00a1a220-b046-4147-9681-95d816e2575c.png>"
      ],
      "metadata": {
        "id": "KPmve-l9hMwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Graph-Structured Representations for  Visual Question Answering"
      ],
      "metadata": {
        "id": "PuCXMA12hZ77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Question Answering 문제에도 그래프를 도입하여 성능을 끌어올릴 수 있다. 아래 그림에 간략히 요약되어 있는데, 장면과 질문으로부터 각각 scene graph와 question graph를 만든 후 pooling과 GRU를 적용한다.\n",
        "\n",
        "<img width=900 src=https://user-images.githubusercontent.com/48666867/149469485-e5f17a26-cca8-4d84-a41f-d832bccb87a4.png>"
      ],
      "metadata": {
        "id": "JoO0ZvoOhiYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Machine Learning for Scent: Learning Generalizable Perceptual Representations of Small Molecules"
      ],
      "metadata": {
        "id": "-j4GlJv2lBf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "분자 구조를 그래프로 변환하고 GNN을 거치면서 138개의 향기를 예측할 수 있다고 한다. <br>\n",
        "기존에는 분자 구조를 분석할 때 Mordred나 fingerprint 방법을 사용했는데 요즘엔 graph neural network를 사용해서 분자 구조를 분석할 수 있다.\n",
        "\n",
        "<img width=900 src=https://user-images.githubusercontent.com/48666867/149471255-b3b8f5ac-c9be-40c5-bb71-4635e14f6a14.png>\n"
      ],
      "metadata": {
        "id": "bFMh8BzYlRPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5 Graph Convolutional Matrix Completion"
      ],
      "metadata": {
        "id": "7Qy-AcNPlpaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "유저-영화 평점 행렬이 있을 때 기존 평점을 기반으로 message passing function을 사용해서 아직 평가가 없는 유저-영화 쌍의 예상 평점을 계산한다.\n",
        "\n",
        "<img width=900 src=https://user-images.githubusercontent.com/48666867/149471667-332645ee-3d9f-4574-b879-f4b5b93ac299.png>\n",
        "<img width=900 src=https://user-images.githubusercontent.com/48666867/149471863-d53df765-85c2-4e6d-8b61-4eff0034f09f.png>"
      ],
      "metadata": {
        "id": "JyPYQY89lynz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refence\n",
        "- papers\n",
        "1. F. Scarselli, M. Gori, “The graph neural network model,” IEEE Transactions on Neural Networks, 2009\n",
        "2. Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, Philip S. Yu, “A Comprehensive Survey on Graph Neural Networks”, arXiv:1901.00596\n",
        "3. T. N. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” in Proc. of ICLR, 2017\n",
        "4. J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl, “Neural Message Passing for Quantum Chemistry”, in Proc. of ICML, 2017\n",
        "5. D. Xu, Y. Zhu, C. B. Choy, and L. Fei-Fei, “Scene graph generation by iterative message passing,” in Proc. of CVPR, 2017\n",
        "6. J. Johnson, A. Gupta, and L. Fei-Fei, “Image generation from scene graphs,” in Proc. of CVPR, 2018\n",
        "7. D. Teney, L. Liu and A. van den Hengel, “Graph-Structured Representations for Visual Question Answering”, in Proc. of CVPR, 2017\n",
        "8. B. Sanchez-Lengeling, J. N. Wei, B. K. Lee, R. C. Gerkin, A. Aspuru-Guzik, and A. B. Wiltschko, “Machine Learning for Scent: Learning Generalizable Perceptual Representations of Small Molecules”, arXiv: 1910.10685\n",
        "9. R. van den Berg, T. N. Kipf, and M. Welling, “Graph Convolutional Matrix Completion”, arXiv:1706.02263\n",
        "\n",
        "- Web\n",
        "1. https://medium.com/watcha/gnn-%EC%86%8C%EA%B0%9C-%EA%B8%B0%EC%B4%88%EB%B6%80%ED%84%B0-%EB%85%BC%EB%AC%B8%EA%B9%8C%EC%A7%80-96567b783479\n",
        "2. https://ganghee-lee.tistory.com/27\n",
        "3. https://data-newbie.tistory.com/707\n"
      ],
      "metadata": {
        "id": "sF4_CvcEmLW8"
      }
    }
  ]
}